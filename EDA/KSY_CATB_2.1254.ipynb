{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tqdm\n",
    "import pdb\n",
    "from scipy.sparse import csr_matrix, linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#import lightgbm as lgb\n",
    "\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '../data/'\n",
    "\n",
    "users = pd.read_csv(path+'users.csv')\n",
    "books = pd.read_csv(path+'books.csv')\n",
    "train_ratings = pd.read_csv(path+'train_ratings.csv')\n",
    "test_ratings = pd.read_csv(path+'test_ratings.csv')\n",
    "submit = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "\n",
    "def rmse(real: list, predict: list) -> float:\n",
    "    pred = np.array(predict)\n",
    "    return np.sqrt(np.mean((real-pred) ** 2))\n",
    "\n",
    "SEED = 42\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "print('users shape: ', users.shape)\n",
    "print('books shape: ', books.shape)\n",
    "print('train_ratings shape: ', train_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 테이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books 테이블 전처리 부분 입니다.\n",
    "# books의 이미지 변수를 지워줍니다.\n",
    "# 제목과 요약 내용 변수를 지웁니다. \n",
    "# (이 변수들은 추후 사용 가능할수도 있으나 일단 지웁니다.)\n",
    "# books의 publisher 변수 중 이름이 비슷한 변수들을 찾아 하나로 통일해줍니다.\n",
    "books.drop(['book_title', 'summary', 'img_url', 'img_path'], axis = 1, inplace = True)\n",
    "\n",
    "books_publishers = books.groupby('publisher')['isbn'].count().sort_values(ascending=False)\n",
    "for i in books_publishers[books_publishers > 20].index: # 20 말고 10으로 하면 오류가 남..\n",
    "    books['publisher'][books['publisher'].str.contains(i)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books의 카테고리 부분.\n",
    "\n",
    "# 대괄호 써있는 카테고리 전치리\n",
    "books.loc[books[books['category'].notnull()].index, 'category'] = books[books['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "# 모두 소문자로 통일\n",
    "books['category'] = books['category'].str.lower()\n",
    "\n",
    "# 수작업으로 higt 카테고리로 통합\n",
    "categories = ['garden','crafts','physics','adventure','music','fiction','nonfiction','science','science fiction','social','homicide',\n",
    " 'sociology','disease','religion','christian','philosophy','psycholog','mathemat','agricult','environmental',\n",
    " 'business','poetry','drama','literary','travel','motion picture','children','cook','literature','electronic',\n",
    " 'humor','animal','bird','photograph','computer','house','ecology','family','architect','camp','criminal','language','india']\n",
    "\n",
    "books['category_high'] = books['category'].copy()\n",
    "for category in categories:\n",
    "    books.loc[books[books['category'].str.contains(category,na=False)].index,'category_high'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['category_high'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language와 category_high NULL 값을 최빈값으로 채웁니다.\n",
    "# 근거 : language == en일 때, category_high == fiction 일 때와\n",
    "# 근거 : 값이 NULL 일 때 rating 평균이 7.0x로 유사한 형태.\n",
    "books['language'].fillna('en', inplace = True)\n",
    "books['category_high'].fillna('fiction', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출판연도 1970, 1980, 1990, 2000, 2020 으로 범주화 시킵니다.\n",
    "# 딥러닝 과정에서 범주화 시키는 것이 유리합니다.\n",
    "# 근거 : develop 파일에서 여러번 실험 결과 본 기준이 가장 rating을 잘 구분함.\n",
    "\n",
    "books['years'] = books['year_of_publication'].copy()\n",
    "books['years'][books['year_of_publication'] < 1970] = 1970\n",
    "books['years'][(books['year_of_publication'] < 1980) * (books['year_of_publication'] >= 1970)] = 1980\n",
    "books['years'][(books['year_of_publication'] < 1990) * (books['year_of_publication'] >= 1980)] = 1990\n",
    "books['years'][(books['year_of_publication'] < 2000) * (books['year_of_publication'] >= 1990)] = 2000\n",
    "books['years'][(books['year_of_publication'] >= 2000)] = 2020\n",
    "books['years'] = books['years'].astype('str')\n",
    "#books['years'] = books['years'].astype('int')\n",
    "books.drop(['year_of_publication', 'category'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 테이블 (미션 1 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['location'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "\n",
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0].strip())\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1].strip())\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2].strip())\n",
    "\n",
    "users = users.replace('na', np.nan) #특수문자 제거로 n/a가 na로 바뀌게 되었습니다. 따라서 이를 컴퓨터가 인식할 수 있는 결측값으로 변환합니다.\n",
    "users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "\n",
    "modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "location = users[(users['location'].str.contains('seattle'))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "\n",
    "location_list = []\n",
    "for location in modify_location:\n",
    "    try:\n",
    "        right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "        location_list.append(right_location)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for location in location_list:\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]\n",
    "\n",
    "loc_city2idx = {v:k for k,v in enumerate(users['location_city'].unique())}\n",
    "loc_state2idx = {v:k for k,v in enumerate(users['location_state'].unique())}\n",
    "loc_country2idx = {v:k for k,v in enumerate(users['location_country'].unique())}\n",
    "\n",
    "users['location_city'] = users['location_city'].map(loc_city2idx)\n",
    "users['location_state'] = users['location_state'].map(loc_state2idx)\n",
    "users['location_country'] = users['location_country'].map(loc_country2idx)\n",
    "\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users['location_city'] = users['location'].apply(lambda x: x.split(',')[0])\n",
    "# users['location_state'] = users['location'].apply(lambda x: x.split(',')[1])\n",
    "# users['location_country'] = users['location'].apply(lambda x: x.split(',')[2])\n",
    "# users = users.drop(['location'], axis=1)\n",
    "\n",
    "# loc_city2idx = {v:k for k,v in enumerate(users['location_city'].unique())}\n",
    "# loc_state2idx = {v:k for k,v in enumerate(users['location_state'].unique())}\n",
    "# loc_country2idx = {v:k for k,v in enumerate(users['location_country'].unique())}\n",
    "\n",
    "# users['location_city'] = users['location_city'].map(loc_city2idx)\n",
    "# users['location_state'] = users['location_state'].map(loc_state2idx)\n",
    "# users['location_country'] = users['location_country'].map(loc_country2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # users 테이블 전처리 입니다.\n",
    "# # location이 지역, 주, 국가로 되어있어 이 부분 기초 전처리 진행 과정입니다.\n",
    "\n",
    "# users['location'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "\n",
    "# # 지역, 주, 국가\n",
    "# users['location_city'] = users['location'].apply(lambda x: x.split(',')[0].strip())\n",
    "# users['location_state'] = users['location'].apply(lambda x: x.split(',')[1].strip())\n",
    "# users['location_country'] = users['location'].apply(lambda x: x.split(',')[2].strip())\n",
    "\n",
    "# users = users.replace('na', np.nan) #특수문자 제거로 n/a가 na로 바뀌게 되었습니다. 따라서 이를 컴퓨터가 인식할 수 있는 결측값으로 변환합니다.\n",
    "# users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "\n",
    "# # 도시는 존재하는데 나라 정보가 없는 경우 채워주는 코드\n",
    "# modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "# location = users[(users['location'].str.contains('seattle'))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "\n",
    "# location_list = []\n",
    "# for location in modify_location:\n",
    "#     try:\n",
    "#         right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "#         location_list.append(right_location)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# for location in location_list:\n",
    "#     users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "#     users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 저는 도시, 주, 국가 중 주를 선택했습니다.\n",
    "# # 우선 모든 변수를 다 쓰는 건 아니라고 생각했어요. 도시 < 주 < 국가로 포함관계가 있기 때문이죠.\n",
    "# # 데이터 분석 결과 주와 국가 단위가 비슷한 경우가 많은 것을 확인했습니다.\n",
    "# # 조그만 섬 국가 < 미국 켈리포니아 주 < 미국 같은 경우죠.\n",
    "# # 미국 같은 경우 미국으로 뭉뚱그리기 보다 주 단위로 나누는 것이 맞다고 판단했습니다.\n",
    "# # 실제 미국 주 별로 rating 차이가 꽤 존재합니다.\n",
    "# # 다만 도시 기준으로 나누면 너무 세분화 될 것 같다는 생각이 들었습니다.\n",
    "# # 결론적으로 주를 지역을 나타내는 변수로 사용하기로 하고 결측값을 도시, 나라에서 채우기로 했습니다.\n",
    "\n",
    "# def _fillna(x):\n",
    "#     if pd.isna(x['location_country']):\n",
    "#         # 만약 나라가 기록 안되있는 경우        \n",
    "#         if pd.isna(x['location_city']):\n",
    "#             # 도시까지 없다면 모든 정보가 없음. 최빈값 california 사용.\n",
    "#             return 'california'\n",
    "#         else:\n",
    "#             tem = users['location_state'][users['location_city'] == x['location_city']].value_counts()\n",
    "#             if len(tem) == 0: \n",
    "#                 # 만약 주 이름이 없는 도시이면 도시 이름을 주 이름으로 사용.\n",
    "#                 return x['location_city'] \n",
    "#             else:\n",
    "#                 # 그 도시에서 가장 자주 쓰이는 주 이름 사용.\n",
    "#                 return tem.index[0]\n",
    "\n",
    "#     else:\n",
    "#         tem = users['location_state'][users['location_country'] == x['location_country']].value_counts()\n",
    "#         if len(tem) == 0: \n",
    "#             # 만약 주 이름이 없는 나라이면 나라이름을 주 이름으로 사용.\n",
    "#             return x['location_country'] \n",
    "#         else:\n",
    "#             # 그 나라에서 가장 자주 쓰이는 주 이름 사용.\n",
    "#             return tem.index[0]\n",
    "\n",
    "# users['fix_location_state'] = users.apply(lambda x : _fillna(x) if pd.isna(x['location_state']) else x['location_state'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['fix_age'] = users['age'].copy()\n",
    "users['fix_age'][users['age'] < 10] = 10\n",
    "users['fix_age'][(users['age'] < 20) & (users['age'] >= 10)] = 20\n",
    "users['fix_age'][(users['age'] < 30) & (users['age'] >= 20)] = 30\n",
    "users['fix_age'][(users['age'] < 35) & (users['age'] >= 30)] = 35\n",
    "users['fix_age'][(users['age'] < 40) & (users['age'] >= 35)] = 40\n",
    "users['fix_age'][(users['age'] < 50) & (users['age'] >= 40)] = 50\n",
    "users['fix_age'][users['age'] >= 50] = 100\n",
    "users['fix_age'].fillna(10, inplace = True)\n",
    "users['fix_age'] = users['fix_age'].astype('str') # users['fix_age'] = users['fix_age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users2 = pd.read_csv(path+'users.csv')\n",
    "# users['age'] = users2['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def age_map(x: int) -> int:\n",
    "#     x = int(x)\n",
    "#     if x < 20:\n",
    "#         return 1\n",
    "#     elif x >= 20 and x < 30:\n",
    "#         return 2\n",
    "#     elif x >= 30 and x < 40:\n",
    "#         return 3\n",
    "#     elif x >= 40 and x < 50:\n",
    "#         return 4\n",
    "#     elif x >= 50 and x < 60:\n",
    "#         return 5\n",
    "#     else:\n",
    "#         return 6\n",
    "\n",
    "# users['age'] = users['age'].fillna(users['age'].mean())\n",
    "# users['age'] = users['age'].apply(age_map)\n",
    "\n",
    "# users['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users[['user_id', 'location_city', 'location_state', 'location_country','fix_age']]\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1\n",
    "\n",
    "# def make_others(_column):\n",
    "#     tem = pd.DataFrame(users[_column].value_counts()).reset_index()\n",
    "#     tem.columns = ['names','count']\n",
    "#     others_list = tem[tem['count'] <= n]['names'].values  # n은 초기에 설정함. 바꿀 수 있음.\n",
    "#     users.loc[users[users[_column].isin(others_list)].index, _column]= 'others'\n",
    "\n",
    "# def make_others2(_column):\n",
    "#     tem = pd.DataFrame(books[_column].value_counts()).reset_index()\n",
    "#     tem.columns = ['names','count']\n",
    "#     others_list = tem[tem['count'] <= n]['names'].values  # n은 초기에 설정함. 바꿀 수 있음.\n",
    "#     books.loc[books[books[_column].isin(others_list)].index, _column]= 'others'\n",
    "\n",
    "# make_others('location_city')\n",
    "# make_others('location_state')\n",
    "# make_others('location_country')\n",
    "\n",
    "# make_others2('book_author')\n",
    "# make_others2('publisher')\n",
    "# make_others2('category_high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rating 테이블과 merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 완료한 books와 users 테이블을 이용해 rating 테이블과 merge 하기.\n",
    "train_ratings = pd.read_csv(path+'train_ratings.csv')\n",
    "test_ratings = pd.read_csv(path+'test_ratings.csv')\n",
    "\n",
    "train_ratings = pd.merge(train_ratings,books, how='right',on='isbn')\n",
    "train_ratings.dropna(subset=['rating'], inplace = True)\n",
    "train_ratings = pd.merge(train_ratings, users, how='right',on='user_id')\n",
    "train_ratings.dropna(subset=['rating'], inplace = True)\n",
    "\n",
    "test_ratings['index'] = test_ratings.index\n",
    "test_ratings = pd.merge(test_ratings,books, how='right',on='isbn')\n",
    "test_ratings.dropna(subset=['rating'], inplace = True)\n",
    "test_ratings = pd.merge(test_ratings, users, how='right',on='user_id')\n",
    "test_ratings.dropna(subset=['rating'], inplace = True)\n",
    "test_ratings = test_ratings.sort_values('index')\n",
    "test_ratings.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "train_ratings['user_id'] = train_ratings['user_id'].astype('str')\n",
    "test_ratings['user_id'] = test_ratings['user_id'].astype('str')\n",
    "\n",
    "train_ratings['location_city'] = train_ratings['location_city'].astype('str')\n",
    "test_ratings['location_city'] = test_ratings['location_city'].astype('str')\n",
    "\n",
    "train_ratings['location_state'] = train_ratings['location_state'].astype('str')\n",
    "test_ratings['location_state'] = test_ratings['location_state'].astype('str')\n",
    "\n",
    "train_ratings['location_country'] = train_ratings['location_country'].astype('str')\n",
    "test_ratings['location_country'] = test_ratings['location_country'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_cat = {\n",
    "#             \"task_type\" : \"GPU\",\n",
    "#             \"devices\" : '0',\n",
    "#             \"random_state\": SEED,\n",
    "#             \"learning_rate\": 0.05,\n",
    "#             \"n_estimators\": 2000,\n",
    "#             \"verbose\" : 1,\n",
    "#             \"objective\" : \"RMSE\",\n",
    "#             \"max_depth\": 10,#trial.suggest_int(\"max_depth\", 1, 16),\n",
    "#             \"colsample_bylevel\": 1,#trial.suggest_float(\"colsample_bylevel\", 0.8, 1.0),\n",
    "#             #\"subsample\": 0.8, #trial.suggest_float(\"subsample\", 0.3, 1.0), GPU 사용시 안될수도.\n",
    "#             \"min_child_samples\": 50, #trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "#             \"max_bin\": 300, #trial.suggest_int(\"max_bin\", 200, 500),\n",
    "#             \"cat_features\" : list(train_ratings.drop(['rating'],axis = 1).columns)\n",
    "#     }\n",
    "\n",
    "params_cat = {\n",
    "    \"task_type\" : \"GPU\",\n",
    "    \"devices\" : '0',\n",
    "    \"random_state\": SEED,\n",
    "    'learning_rate': 0.04574578205475402, \n",
    "    'bagging_temperature': 0.12172958098369972, \n",
    "    'n_estimators': 8459, \n",
    "    'max_depth': 8, \n",
    "    'random_strength': 28, \n",
    "    'l2_leaf_reg': 1.6285455533915874e-05, \n",
    "    'min_child_samples': 18, \n",
    "    'max_bin': 441, \n",
    "    'od_type': 'Iter',\n",
    "    \"cat_features\" : list(train_ratings.drop(['rating'],axis = 1).columns),\n",
    "}\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(train_ratings.drop(['rating'],axis = 1), train_ratings['rating'], test_size=0.2)\n",
    "\n",
    "model = CatBoostRegressor(**params_cat)\n",
    "model.fit(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    #early_stopping_rounds=10,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "cat_pred = model.predict(X_val)\n",
    "log_score = rmse(y_val, cat_pred)\n",
    "\n",
    "print(log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "folds = []\n",
    "for train_idx, valid_idx in skf.split(train_ratings, train_ratings['rating']):\n",
    "  folds.append((train_idx,valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "cat_models={}\n",
    "\n",
    "cat_features = list(range(1, 10))\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"random_state\":SEED, # 42 -> SEED로 변경\n",
    "        \"objective\" : \"RMSE\",\n",
    "        \"cat_features\" : list(train_ratings.drop(['rating'],axis = 1).columns),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "        \"n_estimators\":trial.suggest_int(\"n_estimators\", 1000, 10000),\n",
    "        \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n",
    "        'random_strength' :trial.suggest_int('random_strength', 0, 100),\n",
    "    #   \"colsample_bylevel\":trial.suggest_float(\"colsample_bylevel\", 0.4, 1.0), 이거 때메 GPU 안돌아감\n",
    "        \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**param, task_type = 'GPU', devices = '0')\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    cat_pred = model.predict(X_valid)\n",
    "    log_score = rmse(y_valid, cat_pred)\n",
    "\n",
    "    return log_score\n",
    "\n",
    "for fold in range(0,5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train = train_ratings.drop(['rating'],axis = 1).iloc[train_idx]\n",
    "    X_valid = train_ratings.drop(['rating'],axis = 1).iloc[valid_idx]\n",
    "    y_train = train_ratings['rating'].iloc[train_idx]\n",
    "    y_valid = train_ratings['rating'].iloc[valid_idx]\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=SEED) # 42-> SEED로 변경\n",
    "    study = optuna.create_study(\n",
    "        study_name = 'cat_parameter_opt',\n",
    "        direction = 'minimize',\n",
    "        sampler = sampler,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(**study.best_params, task_type = 'GPU', devices = '0', random_state = SEED, objective = 'RMSE', cat_features = list(train_ratings.drop(['rating'],axis = 1).columns))\n",
    "    model.fit(X_train, y_train)\n",
    "                \n",
    "    pred = model.predict(test_ratings.drop(['rating'],axis = 1))\n",
    "    test_ratings[f'pred_{fold}'] = pred\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings['rating'] = (test_ratings['pred_0'] + test_ratings['pred_1'] + test_ratings['pred_2'] + test_ratings['pred_3'] + test_ratings['pred_4']) / 5\n",
    "test = test_ratings[['user_id', 'isbn', 'rating']]\n",
    "test.to_csv('../submit/KSY_5KFold_Optima2.csv', index = False)\n",
    "test_ratings.to_csv('../data/KSY_5KFold_Optima2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../submit/KSY_5KFold_Optima.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"random_state\":42,\n",
    "        \"objective\" : \"RMSE\",\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "        \"n_estimators\":trial.suggest_int(\"n_estimators\", 1000, 10000),\n",
    "        \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n",
    "        'random_strength' :trial.suggest_int('random_strength', 0, 100),\n",
    "    #   \"colsample_bylevel\":trial.suggest_float(\"colsample_bylevel\", 0.4, 1.0), 이거 때메 GPU 안돌아감\n",
    "        \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "    }\n",
    "    train_x, val_x, train_y, val_y = train_test_split(train_ratings.drop(['rating'],axis = 1), train_ratings['rating'], test_size=0.2)\n",
    "\n",
    "    model = CatBoostRegressor(**param, task_type = 'GPU')\n",
    "\n",
    "    model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        eval_set=[(val_x, val_y)],\n",
    "        cat_features = list(train_ratings.drop(['rating'],axis = 1).columns),\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    cat_pred = model.predict(val_x)\n",
    "    log_score = rmse(val_y, cat_pred)\n",
    "\n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna를 이용해 최적의 Hyperparameter 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name = 'cat_parameter_opt',\n",
    "    direction = 'minimize',\n",
    "    sampler = sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Best Score:\",study.best_value)\n",
    "print(\"Best trial\",study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 중요도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(20,9))\n",
    "\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_feature_importance(model.get_feature_importance(), train_ratings.drop(['rating'],axis = 1).columns, 'CATBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
