{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_row', 50)\n",
    "\n",
    "train = pd.read_csv('../data/train_ratings.csv')\n",
    "test = pd.read_csv('../data/test_ratings.csv')\n",
    "books = pd.read_csv('../data/books.csv')\n",
    "users = pd.read_csv('../data/users.csv')\n",
    "\n",
    "n = 10 # N개 이하 범주는 Others로, N은 유동적으로 할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books 테이블 전처리 부분 입니다.\n",
    "# books의 이미지 변수를 지워줍니다.\n",
    "# 제목과 요약 내용 변수를 지웁니다. \n",
    "# (이 변수들은 추후 사용 가능할수도 있으나 일단 지웁니다.)\n",
    "# books의 publisher 변수 중 이름이 비슷한 변수들을 찾아 하나로 통일해줍니다.\n",
    "books.drop(['book_title', 'summary', 'img_url', 'img_path'], axis = 1, inplace = True)\n",
    "\n",
    "books_publishers = books.groupby('publisher')['isbn'].count().sort_values(ascending=False)\n",
    "for i in books_publishers[books_publishers > 20].index: # 20 말고 10으로 하면 오류가 남..\n",
    "    books['publisher'][books['publisher'].str.contains(i)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books의 카테고리 부분.\n",
    "\n",
    "# 대괄호 써있는 카테고리 전치리\n",
    "books.loc[books[books['category'].notnull()].index, 'category'] = books[books['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "# 모두 소문자로 통일\n",
    "books['category'] = books['category'].str.lower()\n",
    "\n",
    "# 수작업으로 higt 카테고리로 통합\n",
    "categories = ['garden','crafts','physics','adventure','music','fiction','nonfiction','science','science fiction','social','homicide',\n",
    " 'sociology','disease','religion','christian','philosophy','psycholog','mathemat','agricult','environmental',\n",
    " 'business','poetry','drama','literary','travel','motion picture','children','cook','literature','electronic',\n",
    " 'humor','animal','bird','photograph','computer','house','ecology','family','architect','camp','criminal','language','india']\n",
    "\n",
    "books['category_high'] = books['category'].copy()\n",
    "for category in categories:\n",
    "    books.loc[books[books['category'].str.contains(category,na=False)].index,'category_high'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language와 category_high NULL 값을 최빈값으로 채웁니다.\n",
    "# 근거 : language == en일 때, category_high == fiction 일 때와\n",
    "# 근거 : 값이 NULL 일 때 rating 평균이 7.0x로 유사한 형태.\n",
    "books['language'].fillna('en', inplace = True)\n",
    "books['category_high'].fillna('fiction', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출판연도 1970, 1980, 1990, 2000, 2020 으로 범주화 시킵니다.\n",
    "# 딥러닝 과정에서 범주화 시키는 것이 유리합니다.\n",
    "# 근거 : develop 파일에서 여러번 실험 결과 본 기준이 가장 rating을 잘 구분함.\n",
    "\n",
    "books['years'] = books['year_of_publication'].copy()\n",
    "books['years'][books['year_of_publication'] < 1970] = 1970\n",
    "books['years'][(books['year_of_publication'] < 1980) * (books['year_of_publication'] >= 1970)] = 1980\n",
    "books['years'][(books['year_of_publication'] < 1990) * (books['year_of_publication'] >= 1980)] = 1990\n",
    "books['years'][(books['year_of_publication'] < 2000) * (books['year_of_publication'] >= 1990)] = 2000\n",
    "books['years'][(books['year_of_publication'] >= 2000)] = 2020\n",
    "books['years'] = books['years'].astype('int')\n",
    "books['years'] = books['years'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149570 entries, 0 to 149569\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   isbn           149570 non-null  object\n",
      " 1   book_author    149570 non-null  object\n",
      " 2   publisher      149570 non-null  object\n",
      " 3   language       149570 non-null  object\n",
      " 4   category_high  149570 non-null  object\n",
      " 5   years          149570 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# 사용한 변수를 제외하고 전처리가 잘 됬는지 확인합니다.\n",
    "books.drop(['year_of_publication', 'category'], axis = 1, inplace = True)\n",
    "books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일정 개수(n) 이하 작가, 출판사, 언어, 카테고리 변수 모두 Others 취급\n",
    "\n",
    "def make_others(_column):\n",
    "    tem = pd.DataFrame(books[_column].value_counts()).reset_index()\n",
    "    tem.columns = ['names','count']\n",
    "    others_list = tem[tem['count'] < n]['names'].values  # n은 초기에 설정함. 바꿀 수 있음.\n",
    "    books.loc[books[books[_column].isin(others_list)].index, _column]= 'others'\n",
    "\n",
    "make_others('book_author')\n",
    "make_others('publisher')\n",
    "make_others('language')\n",
    "make_others('category_high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users 테이블 전처리 입니다.\n",
    "# location이 지역, 주, 국가로 되어있어 이 부분 기초 전처리 진행 과정입니다.\n",
    "\n",
    "users['location'] = users['location'].str.replace(r'[^0-9a-zA-Z:,]', '') # 특수문자 제거\n",
    "\n",
    "# 지역, 주, 국가\n",
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0].strip())\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1].strip())\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2].strip())\n",
    "\n",
    "users = users.replace('na', np.nan) #특수문자 제거로 n/a가 na로 바뀌게 되었습니다. 따라서 이를 컴퓨터가 인식할 수 있는 결측값으로 변환합니다.\n",
    "users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "\n",
    "# 도시는 존재하는데 나라 정보가 없는 경우 채워주는 코드\n",
    "modify_location = users[(users['location_country'].isna())&(users['location_city'].notnull())]['location_city'].values\n",
    "location = users[(users['location'].str.contains('seattle'))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "\n",
    "location_list = []\n",
    "for location in modify_location:\n",
    "    try:\n",
    "        right_location = users[(users['location'].str.contains(location))&(users['location_country'].notnull())]['location'].value_counts().index[0]\n",
    "        location_list.append(right_location)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for location in location_list:\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_state'] = location.split(',')[1]\n",
    "    users.loc[users[users['location_city']==location.split(',')[0]].index,'location_country'] = location.split(',')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저는 도시, 주, 국가 중 주를 선택했습니다.\n",
    "# 우선 모든 변수를 다 쓰는 건 아니라고 생각했어요. 도시 < 주 < 국가로 포함관계가 있기 때문이죠.\n",
    "# 데이터 분석 결과 주와 국가 단위가 비슷한 경우가 많은 것을 확인했습니다.\n",
    "# 조그만 섬 국가 < 미국 켈리포니아 주 < 미국 같은 경우죠.\n",
    "# 미국 같은 경우 미국으로 뭉뚱그리기 보다 주 단위로 나누는 것이 맞다고 판단했습니다.\n",
    "# 실제 미국 주 별로 rating 차이가 꽤 존재합니다.\n",
    "# 다만 도시 기준으로 나누면 너무 세분화 될 것 같다는 생각이 들었습니다.\n",
    "# 결론적으로 주를 지역을 나타내는 변수로 사용하기로 하고 결측값을 도시, 나라에서 채우기로 했습니다.\n",
    "\n",
    "def _fillna(x):\n",
    "    if pd.isna(x['location_country']):\n",
    "        # 만약 나라가 기록 안되있는 경우        \n",
    "        if pd.isna(x['location_city']):\n",
    "            # 도시까지 없다면 모든 정보가 없음. 최빈값 california 사용.\n",
    "            return 'california'\n",
    "        else:\n",
    "            tem = users['location_state'][users['location_city'] == x['location_city']].value_counts()\n",
    "            if len(tem) == 0: \n",
    "                # 만약 주 이름이 없는 도시이면 도시 이름을 주 이름으로 사용.\n",
    "                return x['location_city'] \n",
    "            else:\n",
    "                # 그 도시에서 가장 자주 쓰이는 주 이름 사용.\n",
    "                return tem.index[0]\n",
    "\n",
    "    else:\n",
    "        tem = users['location_state'][users['location_country'] == x['location_country']].value_counts()\n",
    "        if len(tem) == 0: \n",
    "            # 만약 주 이름이 없는 나라이면 나라이름을 주 이름으로 사용.\n",
    "            return x['location_country'] \n",
    "        else:\n",
    "            # 그 나라에서 가장 자주 쓰이는 주 이름 사용.\n",
    "            return tem.index[0]\n",
    "\n",
    "users['fix_location_state'] = users.apply(lambda x : _fillna(x) if pd.isna(x['location_state']) else x['location_state'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/79916736/197685190-c4b88b82-4a23-4b79-b7a4-1fb849032dd3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 데이터를 바탕으로 나이를 분류합니다. \n",
    "# 이때 10세 미만과 나이가 NULL인 데이터는 상당히 유사한 평점을 메기는 것 같아요.\n",
    "# 그러므로 10세 미만 사용자와 NULL 사용자는 같은 그룹으로 묶습니다. \n",
    "\n",
    "users['fix_age'] = users['age'].copy()\n",
    "users['fix_age'][users['age'] < 10] = 10\n",
    "users['fix_age'][(users['age'] < 20) & (users['age'] >= 10)] = 20\n",
    "users['fix_age'][(users['age'] < 30) & (users['age'] >= 20)] = 30\n",
    "users['fix_age'][(users['age'] < 35) & (users['age'] >= 30)] = 35\n",
    "users['fix_age'][(users['age'] < 40) & (users['age'] >= 35)] = 40\n",
    "users['fix_age'][(users['age'] < 50) & (users['age'] >= 40)] = 50\n",
    "users['fix_age'][users['age'] >= 50] = 100\n",
    "users['fix_age'].fillna(10, inplace = True)\n",
    "users['fix_age'] = users['fix_age'].astype('int')\n",
    "users['fix_age'] = users['fix_age'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68092 entries, 0 to 68091\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   user_id             68092 non-null  int64 \n",
      " 1   fix_location_state  68092 non-null  object\n",
      " 2   fix_age             68092 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# users에서 사용한 변수는 모두 제거합니다.\n",
    "users = users[['user_id', 'fix_location_state', 'fix_age']]\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일정 개수(n) 이하 fix_location_state 범주 모두 Others 취급\n",
    "\n",
    "def make_others2(_column):\n",
    "    tem = pd.DataFrame(users[_column].value_counts()).reset_index()\n",
    "    tem.columns = ['names','count']\n",
    "    others_list = tem[tem['count'] < n]['names'].values  # n은 초기에 설정함. 바꿀 수 있음.\n",
    "    users.loc[users[users[_column].isin(others_list)].index, _column]= 'others'\n",
    "\n",
    "make_others2('fix_location_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n값과 함께 csv 파일로 새로 저장함\n",
    "\n",
    "books.to_csv(f\"../data/ksy_books_{n}n.csv\", index = False)\n",
    "users.to_csv(f\"../data/ksy_users_{n}n.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 완료한 books와 users 테이블을 이용해 rating 테이블과 merge 하기.\n",
    "\n",
    "train_rating = pd.merge(train,books, how='right',on='isbn')\n",
    "train_rating.dropna(subset=['rating'], inplace = True)\n",
    "train_rating = pd.merge(train_rating, users, how='right',on='user_id')\n",
    "train_rating.dropna(subset=['rating'], inplace = True)\n",
    "\n",
    "test['index'] = test.index\n",
    "test_rating = pd.merge(test,books, how='right',on='isbn')\n",
    "test_rating.dropna(subset=['rating'], inplace = True)\n",
    "test_rating = pd.merge(test_rating, users, how='right',on='user_id')\n",
    "test_rating.dropna(subset=['rating'], inplace = True)\n",
    "test_rating = test_rating.sort_values('index')\n",
    "test_rating.drop(['index'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rating.to_csv(f\"../data/ksy_train_rating_{n}n.csv\", index = False)\n",
    "test_rating.to_csv(f\"../data/ksy_test_rating_{n}n.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>index</th>\n",
       "      <th>book_author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>category_high</th>\n",
       "      <th>years</th>\n",
       "      <th>fix_location_state</th>\n",
       "      <th>fix_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11676.0</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Flamingo</td>\n",
       "      <td>en</td>\n",
       "      <td>actresses</td>\n",
       "      <td>2020</td>\n",
       "      <td>california</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>116866.0</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Flamingo</td>\n",
       "      <td>en</td>\n",
       "      <td>actresses</td>\n",
       "      <td>2020</td>\n",
       "      <td>ontario</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>152827.0</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Perennial</td>\n",
       "      <td>en</td>\n",
       "      <td>others</td>\n",
       "      <td>2000</td>\n",
       "      <td>ontario</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>157969.0</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>en</td>\n",
       "      <td>medical</td>\n",
       "      <td>2000</td>\n",
       "      <td>colorado</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>67958.0</td>\n",
       "      <td>0399135782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>2000</td>\n",
       "      <td>idaho</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54967</th>\n",
       "      <td>278543.0</td>\n",
       "      <td>1576734218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76694.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Multnomah</td>\n",
       "      <td>en</td>\n",
       "      <td>family</td>\n",
       "      <td>2000</td>\n",
       "      <td>california</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92535</th>\n",
       "      <td>278563.0</td>\n",
       "      <td>3492223710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76695.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Piper</td>\n",
       "      <td>de</td>\n",
       "      <td>others</td>\n",
       "      <td>2000</td>\n",
       "      <td>wien</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42352</th>\n",
       "      <td>278633.0</td>\n",
       "      <td>1896095186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76696.0</td>\n",
       "      <td>others</td>\n",
       "      <td>others</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>2020</td>\n",
       "      <td>utah</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100165</th>\n",
       "      <td>278668.0</td>\n",
       "      <td>8408044079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76697.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Planeta</td>\n",
       "      <td>en</td>\n",
       "      <td>fiction</td>\n",
       "      <td>2020</td>\n",
       "      <td>madrid</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33881</th>\n",
       "      <td>278851.0</td>\n",
       "      <td>0767907566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76698.0</td>\n",
       "      <td>others</td>\n",
       "      <td>Broadway</td>\n",
       "      <td>en</td>\n",
       "      <td>nature</td>\n",
       "      <td>2020</td>\n",
       "      <td>texas</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id        isbn  rating    index book_author  \\\n",
       "6        11676.0  0002005018     0.0      0.0      others   \n",
       "1463    116866.0  0002005018     0.0      1.0      others   \n",
       "1597    152827.0  0060973129     0.0      2.0      others   \n",
       "1657    157969.0  0374157065     0.0      3.0      others   \n",
       "1912     67958.0  0399135782     0.0      4.0     Amy Tan   \n",
       "...          ...         ...     ...      ...         ...   \n",
       "54967   278543.0  1576734218     0.0  76694.0      others   \n",
       "92535   278563.0  3492223710     0.0  76695.0      others   \n",
       "42352   278633.0  1896095186     0.0  76696.0      others   \n",
       "100165  278668.0  8408044079     0.0  76697.0      others   \n",
       "33881   278851.0  0767907566     0.0  76698.0      others   \n",
       "\n",
       "                   publisher language category_high years fix_location_state  \\\n",
       "6                   Flamingo       en     actresses  2020         california   \n",
       "1463                Flamingo       en     actresses  2020            ontario   \n",
       "1597               Perennial       en        others  2000            ontario   \n",
       "1657    Farrar Straus Giroux       en       medical  2000           colorado   \n",
       "1912        Putnam Pub Group       en       fiction  2000              idaho   \n",
       "...                      ...      ...           ...   ...                ...   \n",
       "54967              Multnomah       en        family  2000         california   \n",
       "92535                  Piper       de        others  2000               wien   \n",
       "42352                 others       en       fiction  2020               utah   \n",
       "100165               Planeta       en       fiction  2020             madrid   \n",
       "33881               Broadway       en        nature  2020              texas   \n",
       "\n",
       "       fix_age  \n",
       "6           10  \n",
       "1463        10  \n",
       "1597        50  \n",
       "1657        35  \n",
       "1912        40  \n",
       "...        ...  \n",
       "54967       40  \n",
       "92535       40  \n",
       "42352       10  \n",
       "100165      50  \n",
       "33881       35  \n",
       "\n",
       "[76699 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rating = pd.merge(test,books, how='right',on='isbn')\n",
    "test_rating.dropna(subset=['rating'], inplace = True)\n",
    "test_rating = pd.merge(test_rating, users, how='right',on='user_id')\n",
    "test_rating.dropna(subset=['rating'], inplace = True)\n",
    "test_rating = test_rating.sort_values('index')\n",
    "test_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
